{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT NO 7... (Files and exceptional handling assignment )**"
      ],
      "metadata": {
        "id": "nSQoI9sKgxp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1.Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "ZrJAYVkwgkEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multithreading is Preferable\n",
        "\n",
        "1)I/O-bound tasks:\n",
        "If the program spends a lot of time waiting for external resources (like reading/writing files, network operations, or database queries), multithreading is usually more efficient. Since I/O-bound tasks often involve waiting, threads can remain active while waiting, allowing other threads to continue execution.\n",
        "\n",
        "Ex: A web crawler fetching multiple web pages simultaneously, or a server handling multiple client requests at the same time.\n",
        "\n",
        "2)Shared memory:\n",
        "In situations where multiple threads need to work on the same data (and modifications of data by one thread need to be visible to others), multithreading is advantageous. Threads share the same memory space, so it's easier to communicate and share resources between them without the overhead of inter-process communication (IPC).\n",
        "\n",
        "Ex: Real-time data processing in financial systems where threads work on shared datasets with minimal overhead for communication.\n",
        "\n",
        "3)Lower memory overhead:\n",
        "Since threads run in the same memory space as the parent process, they consume less memory than processes, making multithreading preferable in memory-constrained environments.\n",
        "\n",
        "Ex: Applications like a game engine where many tasks need to run in parallel but memory usage is a concern.\n",
        "\n",
        "**Multiprocessing is Preferable:**\n",
        "\n",
        "1)CPU-bound tasks:\n",
        "If the task is CPU-intensive (i.e., tasks that require a lot of computation), multiprocessing is more effective. Python’s Global Interpreter Lock (GIL) restricts CPU-bound tasks in multithreaded Python programs, so creating multiple processes allows better utilization of multiple CPU cores.\n",
        "\n",
        "Example: Data analysis, machine learning model training, or any computationally heavy task like video encoding or image processing.\n",
        "\n",
        "2)Independent processes:\n",
        "When different parts of the program are largely independent and don't need to share state or memory, multiprocessing is a better choice. Each process has its own memory space, which avoids race conditions and the need for synchronization mechanisms.\n",
        "\n",
        "Example: Running independent simulations where each simulation runs in isolation, such as Monte Carlo simulations or genetic algorithms.\n",
        "\n",
        "3)Avoiding GIL limitations (in Python):\n",
        "Python’s GIL prevents multiple threads from executing Python bytecode in parallel. Multiprocessing sidesteps this issue entirely by creating separate processes, each with its own Python interpreter and memory space.\n",
        "\n",
        "Example: Numerical computations using libraries like NumPy or SciPy, which are CPU-bound.\n",
        "\n"
      ],
      "metadata": {
        "id": "I5aJ3DGxhN6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "tKzscyPdiMgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A process pool is a collection of worker processes that are pre-created and managed to efficiently execute tasks in parallel. It allows a program to manage and execute multiple processes without having to manually create and manage each process individually.\n",
        "\n",
        "Characteristics of a Process Pool:\n",
        "\n",
        "Pre-allocation of worker processes:\n",
        "Instead of spawning a new process for every task, a process pool creates a fixed number of worker processes ahead of time. These processes are kept alive and can be reused for multiple tasks, minimizing the overhead of creating and destroying processes repeatedly.\n",
        "\n",
        "Task submission:\n",
        "Tasks are submitted to the process pool, which assigns them to the available worker processes. If all workers are busy, the tasks wait in a queue until a worker becomes available. This ensures efficient utilization of system resources.\n",
        "\n",
        "Load balancing:\n",
        "The pool automatically manages task assignment to workers, balancing the load across multiple processes. The developer doesn’t have to manually manage which task goes to which process.\n",
        "\n",
        "**Manage Multiple Processes Efficiently:**\n",
        "\n",
        "1)Reduced Overhead:\n",
        "Creating and destroying processes has a significant overhead due to the need to allocate memory, initialize resources, and start a new environment for each process. A process pool mitigates this by pre-creating a fixed number of processes and reusing them for multiple tasks, reducing the need to constantly create and destroy processes.\n",
        "\n",
        "2)Efficient Resource Utilization:\n",
        "By limiting the number of active processes, a process pool prevents overloading the system with too many processes. This ensures the system doesn’t run out of resources (e.g., memory, file handles) and that the tasks are spread across the available CPU cores efficiently.\n",
        "\n",
        "3)Task Queueing:\n",
        "If all the worker processes in the pool are busy, additional tasks are placed in a queue. The pool automatically assigns tasks to workers as soon as they are free, enabling efficient task management without the need for manual tracking.\n",
        "\n"
      ],
      "metadata": {
        "id": "-xLnLYWAicjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "w5iGt4k9i5Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiprocessing is a technique used in computing to execute multiple processes (independent programs or tasks) simultaneously, leveraging multiple CPU cores to increase performance. Each process runs independently, with its own memory space and system resources, allowing true parallel execution of tasks.\n",
        "\n",
        "**Why Multiprocessing is Used in Python:**\n",
        "1)Bypassing the Global Interpreter Lock (GIL):\n",
        "Python’s GIL is a mechanism that allows only one thread to execute Python bytecode at a time, even on multi-core systems. This means that Python's built-in threading cannot fully utilize multiple CPU cores for CPU-bound tasks.\n",
        "Multiprocessing avoids this limitation by creating separate processes, each with its own GIL and memory space. This allows multiple processes to run in true parallel, fully utilizing the CPU cores.\n",
        "\n",
        "2)True Parallelism:\n",
        "In Python, multithreading (due to the GIL) only achieves concurrency for I/O-bound tasks (like reading files or network operations), but for CPU-bound tasks, it cannot achieve true parallelism.\n",
        "With multiprocessing, multiple processes run in parallel on different CPU cores, making it ideal for CPU-heavy operations like data analysis, machine learning, image processing, and numerical computation.\n",
        "\n",
        "3)Better Resource Isolation:\n",
        "Each process in the multiprocessing module runs in its own memory space. This ensures that data in one process is isolated from other processes, reducing the risk of race conditions and bugs caused by shared memory.\n",
        "This isolation also increases fault tolerance, as a crash in one process does not affect the others.\n",
        "\n",
        "4)Efficient Use of Multi-core Processors:\n",
        "Modern CPUs have multiple cores, and multiprocessing allows Python programs to utilize all available cores effectively. This improves the performance of tasks that can be parallelized by distributing the workload across multiple processes.\n",
        "For example, an application that processes large datasets can divide the data into smaller chunks, each processed by a separate process, significantly speeding up the overall computation."
      ],
      "metadata": {
        "id": "NO_FC_r_i-JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock."
      ],
      "metadata": {
        "id": "qJd04mgOjskB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared resource (the list)\n",
        "shared_list = []\n",
        "\n",
        "# Lock object to prevent race conditions\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function for the adding thread\n",
        "def add_to_list():\n",
        "    for i in range(1, 11):\n",
        "        with lock:  # Acquire the lock before modifying the list\n",
        "            print(f\"Adding {i} to the list.\")\n",
        "            shared_list.append(i)\n",
        "        time.sleep(0.5)  # Simulate some delay\n",
        "\n",
        "# Function for the removing thread\n",
        "def remove_from_list():\n",
        "    for i in range(1, 11):\n",
        "        time.sleep(0.7)  # Simulate delay to allow adding thread to fill some items\n",
        "        with lock:  # Acquire the lock before modifying the list\n",
        "            if shared_list:\n",
        "                removed_item = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_item} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "# Create threads\n",
        "add_thread = threading.Thread(target=add_to_list)\n",
        "remove_thread = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Start the threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkZjpQJcj_G5",
        "outputId": "0358cd0f-a236-4486-8fef-4c05af153980"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 1 to the list.\n",
            "Adding 2 to the list.\n",
            "Removed 1 from the list.\n",
            "Adding 3 to the list.\n",
            "Removed 2 from the list.\n",
            "Adding 4 to the list.\n",
            "Adding 5 to the list.\n",
            "Removed 3 from the list.\n",
            "Adding 6 to the list.\n",
            "Removed 4 from the list.\n",
            "Adding 7 to the list.\n",
            "Adding 8 to the list.\n",
            "Removed 5 from the list.\n",
            "Adding 9 to the list.\n",
            "Removed 6 from the list.\n",
            "Adding 10 to the list.\n",
            "Removed 7 from the list.\n",
            "Removed 8 from the list.\n",
            "Removed 9 from the list.\n",
            "Removed 10 from the list.\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes"
      ],
      "metadata": {
        "id": "2-3f1imMkS_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sharing Data Between Threads:\n",
        "\n",
        "a) Locks (threading.Lock)\n",
        "A lock (or mutex) is the most basic mechanism for preventing race conditions. It ensures that only one thread can access a shared resource (such as a list, dictionary, or file) at a time by acquiring the lock before accessing the resource and releasing it afterward."
      ],
      "metadata": {
        "id": "khs4TJpNkUXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def critical_section():\n",
        "    with lock:  # Only one thread can enter this block at a time\n",
        "        # Access shared resource safely here\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "be63aMBKk5wh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) RLocks (threading.RLock)\n",
        "An RLock (reentrant lock) is a more flexible lock that allows a thread to acquire the same lock multiple times"
      ],
      "metadata": {
        "id": "md2ALeXTk-to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lock = threading.RLock()\n",
        "with lock:\n",
        "    # Safely access shared resources, even if the lock is re-acquired\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "xYZMeJ3KlCaJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Condition Variables (threading.Condition)\n",
        "A condition variable allows one or more threads to wait until a specific condition is met before continuing execution. It is often used with a Lock to allow threads to wait for a condition and be notified when that condition occurs (e.g., when shared data changes)."
      ],
      "metadata": {
        "id": "HFEYhObdlHEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Events (threading.Event)\n",
        "An event is a simple mechanism for signaling between threads."
      ],
      "metadata": {
        "id": "vO1cXiK0lH8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event = threading.Event()\n",
        "\n",
        "def thread_function():\n",
        "    event.wait()  # Wait until another thread sets the event\n",
        "    # Safely access shared data\n",
        "\n",
        "# Another thread sets the event\n",
        "event.set()\n"
      ],
      "metadata": {
        "id": "thkhk4LylO7I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 2)Sharing Data Between Processes:**"
      ],
      "metadata": {
        "id": "hUZjGtKflVMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Multiprocessing Queue (multiprocessing.Queue)\n",
        "A multiprocessing queue is similar to queue.Queue, but it is designed for communication between processes. It allows safe exchange of data between processes by serializing the objects."
      ],
      "metadata": {
        "id": "Ad-BTaS0leQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "q = Queue()\n",
        "\n",
        "def producer():\n",
        "    q.put(42)  # Add data to the queue\n",
        "\n",
        "def consumer():\n",
        "    print(q.get())  # Retrieve data from the queue\n",
        "\n",
        "p1 = Process(target=producer)\n",
        "p2 = Process(target=consumer)\n",
        "p1.start()\n",
        "p2.start()\n",
        "p1.join()\n",
        "p2.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8I_UVO-lqm3",
        "outputId": "35a7319b-6bef-4d3d-abb8-d3b3d5d07b57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " b)Pipes (multiprocessing.Pipe)\n",
        "A pipe provides a two-way communication channel between two processes. One end of the pipe is used to send data, and the other end to receive it. It is faster than queues but limited to two processes."
      ],
      "metadata": {
        "id": "pyiPFYPFmE_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "\n",
        "def child():\n",
        "    child_conn.send(\"Hello from the child process\")\n",
        "\n",
        "p = Process(target=child)\n",
        "p.start()\n",
        "print(parent_conn.recv())\n",
        "p.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dNgXLp4mJsY",
        "outputId": "e5b9a960-3df5-4a3a-8cdc-b7ad9e484aad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from the child process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Shared Memory (multiprocessing.Value, multiprocessing.Array)\n",
        "The multiprocessing module provides Value and Array objects for sharing data between processes using shared memory. These allow for shared, mutable data (like integers or arrays) to be stored in memory that is accessible by multiple processes.\n",
        "\n",
        "Value is used to share a single data item.\n",
        "Array is used to share a fixed-size array."
      ],
      "metadata": {
        "id": "TscL8OstmUY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Manager (multiprocessing.Manager)\n",
        "A multiprocessing manager allows processes to share more complex data structures like lists, dictionaries, and queues."
      ],
      "metadata": {
        "id": "iCvSt5d9mYVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Manager\n",
        "\n",
        "manager = Manager()\n",
        "shared_list = manager.list()  # Create a shared list\n",
        "\n",
        "def add_item():\n",
        "    shared_list.append(42)\n",
        "\n",
        "p1 = Process(target=add_item)\n",
        "p1.start()\n",
        "p1.join()\n",
        "\n",
        "print(shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmlTdFktmc2S",
        "outputId": "d74046ae-bb47-485c-bba1-d61f613311a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.discuss why it's curical to handle exception in concurrent program and the techniques available for doing so."
      ],
      "metadata": {
        "id": "H-Aw0T3JmslC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling exceptions in concurrent programs is crucial for ensuring program reliability, preventing deadlocks or resource leaks, and maintaining overall program stability.\n",
        "\n",
        "**Exception Handling is Crucial in Concurrent Programs:**\n",
        "1)Preventing Program Crashes:\n",
        "In a multithreaded or multiprocessing program, if an exception is raised in one thread or process without being handled, it can terminate that thread or process. In some cases, this can crash the entire program or leave other parts of the program in an undefined state. Handling exceptions ensures that the program can gracefully recover or shut down without crashing unexpectedly.\n",
        "\n",
        "2)Ensuring Proper Resource Management:\n",
        "If an exception occurs during the use of shared resources (like files, memory, or locks), the resources may not be properly released. For example, a thread might acquire a lock but not release it if an exception occurs, leading to deadlocks or resource contention. Exception handling ensures that resources are always cleaned up, even in the event of an error.\n",
        "\n",
        "3)Maintaining Data Integrity:\n",
        "In concurrent programs, race conditions and inconsistent data states can occur when threads or processes modify shared data. If an exception occurs midway through modifying shared data, the data can be left in a partially updated state. Exception handling helps to prevent inconsistent data by rolling back changes or ensuring proper synchronization.\n",
        "\n",
        "4)Diagnosing and Debugging:\n",
        "Without proper exception handling, errors in concurrent programs may go unnoticed, leading to silent failures or bugs that are difficult to diagnose. By handling exceptions explicitly, you can log errors, collect diagnostic information, and make debugging easier."
      ],
      "metadata": {
        "id": "q-imfTeNnczw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Techniques for Handling Exceptions in Concurrent Programs:**\n",
        "\n",
        "1)Try-Except Blocks in Threads or Processes:\n",
        "The most basic way to handle exceptions in concurrent code is to wrap critical sections of code in try-except blocks within each thread or process.\n"
      ],
      "metadata": {
        "id": "sMbbH47ooTdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def thread_function():\n",
        "    try:\n",
        "        # Perform some operation that might raise an exception\n",
        "        result = 10 / 0  # This will raise a ZeroDivisionError\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in thread: {e}\")\n",
        "        # Handle the exception or log the error\n",
        "    finally:\n",
        "        print(\"Thread completed.\")\n",
        "\n",
        "t = threading.Thread(target=thread_function)\n",
        "t.start()\n",
        "t.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjyCRmRQozQA",
        "outputId": "b5b88b63-9bb4-4bdd-c407-772f115fc9e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in thread: division by zero\n",
            "Thread completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)Using concurrent.futures Exception Handling:\n",
        "The concurrent.futures module simplifies managing threads and processes. When using ThreadPoolExecutor or ProcessPoolExecutor, exceptions can be handled when retrieving the results of tasks using futures."
      ],
      "metadata": {
        "id": "HKCrwHSEqCop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def task(n):\n",
        "    return 10 / n\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(task, 0)  # This will raise a ZeroDivisionError\n",
        "    try:\n",
        "        result = future.result()  # Will raise the exception\n",
        "    except Exception as e:\n",
        "        print(f\"Exception in task: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy5dYf7mqJQx",
        "outputId": "5e915ead-62e2-4964-ae44-3dc44495959f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in task: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)Global Exception Handlers:\n",
        "In multithreaded programs, if you want to handle uncaught exceptions globally, you can use custom exception hooks."
      ],
      "metadata": {
        "id": "ILyzCb60qPHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def handle_thread_exception(args):\n",
        "    print(f\"Unhandled exception in thread {args.thread.name}: {args.exc_value}\")\n",
        "\n",
        "threading.excepthook = handle_thread_exception\n",
        "\n",
        "def thread_function():\n",
        "    raise ValueError(\"An error occurred in the thread.\")\n",
        "\n",
        "t = threading.Thread(target=thread_function)\n",
        "t.start()\n",
        "t.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLr_m3FeqRqQ",
        "outputId": "64c64054-b4fd-45d6-8e06-18747d00e2c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unhandled exception in thread Thread-15 (thread_function): An error occurred in the thread.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4)Using multiprocessing Exception Handling:\n",
        "In the multiprocessing module, exceptions raised in child processes do not propagate back to the parent process by default."
      ],
      "metadata": {
        "id": "SLS6mb4dqXgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def task(n):\n",
        "    return 10 / n\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(2) as pool:\n",
        "        results = pool.apply_async(task, (0,))  # This will raise ZeroDivisionError\n",
        "        try:\n",
        "            print(results.get())  # Will raise the exception\n",
        "        except Exception as e:\n",
        "            print(f\"Exception in process: {e}\")\n",
        "v"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "upL8X40rqYjw",
        "outputId": "419e71a3-db41-4855-d531-f0493c33255a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in process: division by zero\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'v' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3df48d1f0863>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception in process: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gm-Vvrokqm2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(2, n+1):\n",
        "        result *= i\n",
        "    return f\"Factorial of {n} is {result}\"\n",
        "\n",
        "# List of numbers from 1 to 10\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Create a thread pool with ThreadPoolExecutor\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks to the thread pool\n",
        "    futures = [executor.submit(factorial, num) for num in numbers]\n",
        "\n",
        "    # Process the results as they complete\n",
        "    for future in as_completed(futures):\n",
        "        print(future.result())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6C66fbbqxOa",
        "outputId": "9648820a-8fb4-468e-bce3-fd1a6f8ef245"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 2 is 2\n",
            "Factorial of 1 is 1\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n",
            "Factorial of 3 is 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes)\n"
      ],
      "metadata": {
        "id": "cRjGsDMtrA_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def compute_square(x):\n",
        "    return x * x\n",
        "\n",
        "def compute_squares_in_parallel(pool_size):\n",
        "    numbers = list(range(1, 11))\n",
        "\n",
        "    # Create a multiprocessing pool\n",
        "    pool = multiprocessing.Pool(processes=pool_size)\n",
        "\n",
        "    # Measure the time taken\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use the pool to compute squares in parallel\n",
        "    results = pool.map(compute_square, numbers)\n",
        "\n",
        "    # Close the pool and wait for the work to finish\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    # Calculate elapsed time\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Pool size: {pool_size}, Time taken: {elapsed_time:.4f} seconds\")\n",
        "    print(\"Results:\", results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pool_sizes = [2, 4, 8]  # Try different pool sizes\n",
        "    for size in pool_sizes:\n",
        "        compute_squares_in_parallel(size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZTtohFTrcxZ",
        "outputId": "7af808c3-5c84-4d2a-ce03-73c2becf646c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Time taken: 0.0120 seconds\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Pool size: 4, Time taken: 0.0193 seconds\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Pool size: 8, Time taken: 0.0434 seconds\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    }
  ]
}